{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoE90j4RaumK"
      },
      "source": [
        "# 08 - Transformer Encoder-Decoder\n",
        "\n",
        "Neste notebook, vamos implementar um modelo encoder-decoder baseado no **Transformer**, uma arquitetura que substituiu as RNNs em muitas tarefas de NLP e se tornou o padrão em tradução automática e modelos de linguagem modernos.\n",
        "\n",
        "## Objetivos de Aprendizado\n",
        "- Revisar a arquitetura do Transformer e seus principais componentes (Self-Attention, Encoder, Decoder)\n",
        "- Implementar o Encoder e o Decoder com PyTorch\n",
        "- Construir um modelo completo de tradução português-inglês usando Transformer\n",
        "- Treinar o modelo em um conjunto de dados de exemplo\n",
        "- Avaliar a qualidade das traduções geradas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vaRzxrPXyIQR"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from collections import Counter\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fCMIS7t82sou"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6r4fbXOaumX"
      },
      "source": [
        "### Positional Encoding\n",
        "\n",
        "Transformers não possuem mecanismos recorrentes ou convolucionais, o que significa que eles não têm uma noção implícita da ordem dos tokens em uma sequência. Para incorporar essa informação, é adicionada uma codificação posicional aos vetores de embedding. Essa codificação é determinística e baseada em funções senoidais de diferentes frequências.\n",
        "\n",
        "A codificação posicional utilizada segue a formulação original do paper *\"Attention is All You Need\"*:\n",
        "\n",
        "$$\n",
        "PE_{(pos, 2i)} = \\sin\\left(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\right)\n",
        "$$\n",
        "\n",
        "$$\n",
        "PE_{(pos, 2i+1)} = \\cos\\left(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\right)\n",
        "$$\n",
        "\n",
        "Onde:\n",
        "- $pos$ representa a posição do token na sequência,\n",
        "- $i$ é o índice da dimensão do embedding,\n",
        "- $d_{\\text{model}}$ é a dimensionalidade do embedding.\n",
        "\n",
        "O resultado é uma matriz de codificação com forma $(1, \\text{max\\_len}, d_{\\text{model}})$ que é somada diretamente aos embeddings de entrada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "I-ve0d5ZaumY"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # matriz (max_len, d_model)\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  # (max_len, 1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        # seno nas posições pares, cosseno nas ímpares\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)  # pares\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)  # ímpares\n",
        "\n",
        "        pe = pe.unsqueeze(0)  # (1, max_len, d_model) -> broadcast no batch\n",
        "        self.register_buffer(\"pe\", pe)  # não é parâmetro treinável\n",
        "\n",
        "    def forward(self, x):\n",
        "        T = x.size(1)\n",
        "        x = x + self.pe[:, :T, :]  # (B, T, d_model)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7yTrjt2aumY",
        "outputId": "71a875a1-2d25-4f7e-d693-dad3cac4abcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positional Encoding: torch.Size([2, 5, 16])\n"
          ]
        }
      ],
      "source": [
        "d_model = 16\n",
        "num_heads = 4\n",
        "B, T = 2, 5\n",
        "\n",
        "# embeddings simulados\n",
        "x = torch.randn(B, T, d_model)\n",
        "\n",
        "# positional encoding\n",
        "pos_enc = PositionalEncoding(d_model)\n",
        "x = pos_enc(x)  # adiciona posições\n",
        "\n",
        "print(\"Positional Encoding:\", x.shape)  # (B, T, d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFuuUyXqaumZ"
      },
      "source": [
        "### Multi-Head Attention\n",
        "\n",
        "O mecanismo de **multi-head attention** é um dos blocos centrais dos Transformers. Ele permite que o modelo foque em diferentes partes da sequência em paralelo, usando múltiplas \"cabeças\" de atenção. Cada cabeça realiza uma atenção com projeções diferentes dos vetores de entrada, e seus resultados são combinados ao final.\n",
        "\n",
        "A atenção é baseada no mecanismo de **Scaled Dot-Product Attention**, que recebe três vetores: $Q$ (query), $K$ (key) e $V$ (value). O cálculo da atenção segue a fórmula:\n",
        "\n",
        "$$\n",
        "\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right) V\n",
        "$$\n",
        "\n",
        "Onde:\n",
        "- $Q$, $K$ e $V$ são tensores projetados a partir da entrada,\n",
        "- $d_k$ é a dimensionalidade das chaves (key),\n",
        "- A divisão por $\\sqrt{d_k}$ serve para normalizar os scores e evitar valores muito grandes que podem saturar a softmax.\n",
        "\n",
        "No caso de múltiplas cabeças, os vetores $Q$, $K$ e $V$ são divididos em $h$ partes (cabeças), cada uma com dimensionalidade reduzida $d_k = d_{\\text{model}} / h$, aplicando a atenção de forma independente em cada cabeça. Os resultados são então concatenados e projetados novamente com uma camada linear:\n",
        "\n",
        "$$\n",
        "\\text{MultiHead}(Q, K, V) = \\text{Concat}(\\text{head}_1, \\dots, \\text{head}_h) W^O\n",
        "$$\n",
        "\n",
        "Cada cabeça é computada como:\n",
        "\n",
        "$$\n",
        "\\text{head}_i = \\text{Attention}(Q W_i^Q, K W_i^K, V W_i^V)\n",
        "$$\n",
        "\n",
        "Esse paralelismo permite que diferentes aspectos contextuais da sequência sejam aprendidos simultaneamente. Essa implementação define todas as projeções lineares necessárias, faz o `split_heads`, aplica a atenção escalada, combina os resultados com `combine_heads`, e projeta de volta para o espaço original com uma camada linear $W^O$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QTIz1sF1auma"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0, \"d_model deve ser divisível por num_heads\"\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_model // num_heads\n",
        "\n",
        "        # Projeções lineares\n",
        "        self.q_proj = nn.Linear(d_model, d_model)\n",
        "        self.k_proj = nn.Linear(d_model, d_model)\n",
        "        self.v_proj = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.out_proj = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        B, Tq, _ = q.size()\n",
        "        Tk = k.size(1)\n",
        "        Tv = v.size(1)\n",
        "\n",
        "        # Projeções\n",
        "        Q = self.q_proj(q)\n",
        "        K = self.k_proj(k)\n",
        "        V = self.v_proj(v)\n",
        "\n",
        "        # Split heads\n",
        "        Q = Q.view(B, Tq, self.num_heads, self.head_dim).transpose(1, 2)  # (B, h, Tq, d_head)\n",
        "        K = K.view(B, Tk, self.num_heads, self.head_dim).transpose(1, 2)  # (B, h, Tk, d_head)\n",
        "        V = V.view(B, Tv, self.num_heads, self.head_dim).transpose(1, 2)  # (B, h, Tv, d_head)\n",
        "\n",
        "        # Atenção\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / (self.head_dim ** 0.5)  # (B, h, Tq, Tk)\n",
        "\n",
        "        if mask is not None:\n",
        "            # mask: (B, 1, 1, Tk) ou (B, 1, Tq, Tk)\n",
        "            attn_scores = attn_scores.masked_fill(mask == 0, float(\"-inf\"))\n",
        "\n",
        "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
        "        attn_output = torch.matmul(attn_weights, V)  # (B, h, Tq, d_head)\n",
        "\n",
        "        # Junta os heads\n",
        "        attn_output = attn_output.transpose(1, 2).contiguous().view(B, Tq, self.d_model)\n",
        "\n",
        "        return self.out_proj(attn_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7bUm8f9saumb"
      },
      "outputs": [],
      "source": [
        "def causal_mask(seq_len, device=None):\n",
        "    \"\"\"\n",
        "    Cria máscara causal triangular inferior.\n",
        "    shape: (1, 1, seq_len, seq_len)\n",
        "    \"\"\"\n",
        "    mask = torch.tril(torch.ones(seq_len, seq_len, device=device))\n",
        "    return mask.unsqueeze(0).unsqueeze(0)  # (1, 1, T, T)\n",
        "\n",
        "\n",
        "def padding_mask(pad_tokens, device=None):\n",
        "    \"\"\"\n",
        "    Cria máscara de padding.\n",
        "    pad_tokens: tensor (B, T) com 1 onde é token válido e 0 onde é padding\n",
        "    retorna shape: (B, 1, 1, T) -> broadcast em atenção\n",
        "    \"\"\"\n",
        "    return pad_tokens.unsqueeze(1).unsqueeze(2).to(device)  # (B,1,1,T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWMguW_Kaumc",
        "outputId": "b4c2d001-d4a6-41fa-f358-1df1d72c85c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Self-Attention: torch.Size([2, 5, 16])\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de uso\n",
        "d_model = 16\n",
        "num_heads = 4\n",
        "B, T = 2, 5\n",
        "\n",
        "x = torch.randn(B, T, d_model)\n",
        "mask = causal_mask(T, device=x.device)\n",
        "attn = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
        "\n",
        "out = attn(x, x, x, mask=mask)\n",
        "print(\"Self-Attention:\", out.shape)  # (B, T, d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evcC70ykaumd"
      },
      "source": [
        "### Feed-Forward Layer\n",
        "\n",
        "Em Transformers, cada bloco contém uma **camada feed-forward totalmente conectada** que é aplicada de forma independente a cada posição da sequência. Essa camada é responsável por aprender transformações não-lineares locais após o mecanismo de atenção.\n",
        "\n",
        "A arquitetura típica de uma feed-forward layer é composta por duas camadas lineares com uma função de ativação não-linear (geralmente ReLU) no meio:\n",
        "\n",
        "$$\n",
        "\\text{FFN}(x) = W_2 \\cdot \\text{ReLU}(W_1 \\cdot x + b_1) + b_2\n",
        "$$\n",
        "\n",
        "Onde:\n",
        "- $x$ é o vetor de entrada de dimensão $d_{\\text{model}}$,\n",
        "- $W_1 \\in \\mathbb{R}^{d_{\\text{ff}} \\times d_{\\text{model}}}$ e $W_2 \\in \\mathbb{R}^{d_{\\text{model}} \\times d_{\\text{ff}}}$ são pesos aprendidos,\n",
        "- $d_{\\text{ff}}$ é a dimensionalidade intermediária (maior que $d_{\\text{model}}$ para aumentar a capacidade do modelo),\n",
        "- $\\text{ReLU}(x) = \\max(0, x)$ é a função de ativação não-linear.\n",
        "\n",
        "Essa camada é aplicada posição a posição (de forma independente em cada token), e introduz não-linearidades e capacidade de transformação mais complexa ao modelo, além de expandir e comprimir a dimensionalidade, o que funciona como um \"bottleneck\" informativo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kc5gpf2V6cSY"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.dropout(self.relu(self.fc1(x))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIdNo5lfaume",
        "outputId": "40bf07cb-9f2a-42ca-e67d-dff137ed0124"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([2, 5, 512])\n",
            "Output shape: torch.Size([2, 5, 512])\n"
          ]
        }
      ],
      "source": [
        "# Exemplo\n",
        "d_model = 512\n",
        "d_ff = 2048\n",
        "B, T = 2, 5\n",
        "\n",
        "feed_forward = FeedForward(d_model, d_ff)\n",
        "\n",
        "query = torch.randn(B, T, d_model)  # (B, T, d_model)\n",
        "output = feed_forward(query)\n",
        "\n",
        "print(f'Input shape: {query.shape}')  # Input shape: (B, T, d_model)\n",
        "print(f'Output shape: {output.shape}')  # Output shape: (B, T, d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-0uuUK5aume"
      },
      "source": [
        "### EncoderLayer e Encoder\n",
        "\n",
        "Cada `EncoderLayer` é composta por dois blocos: atenção multi-cabeça seguida de normalização, e uma feed-forward seguida de outra normalização. Em ambos os casos, há conexões residuais e dropout:\n",
        "\n",
        "$$\n",
        "x_1 = \\text{LayerNorm}(x + \\text{Dropout}(\\text{MultiHead}(x, x, x)))\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{Output} = \\text{LayerNorm}(x_1 + \\text{Dropout}(\\text{FFN}(x_1)))\n",
        "$$\n",
        "\n",
        "A classe `Encoder` empilha múltiplas `EncoderLayer`s após converter os tokens com `Embedding` e adicionar codificações posicionais. O fluxo é:\n",
        "\n",
        "$$\n",
        "x = \\text{Embedding}(x) + \\text{PositionalEncoding}\n",
        "$$\n",
        "\n",
        "$$\n",
        "x = \\text{EncoderLayer}_N \\circ \\cdots \\circ \\text{EncoderLayer}_1 (x)\n",
        "$$\n",
        "\n",
        "Esse processo transforma a sequência de entrada em uma representação contextualizada, onde cada posição é influenciada pelas demais."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ce-MVk6t6eSl"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.feed_forward  = FeedForward(d_model, d_ff)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, src_mask=None):\n",
        "        # Self-Attention\n",
        "        attn_out = self.self_attn(x, x, x, mask=src_mask)\n",
        "        x = x + self.dropout(attn_out)\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        # FeedForward\n",
        "        ff_out = self.feed_forward(x)\n",
        "        x = x + self.dropout(ff_out)\n",
        "        x = self.norm2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIKZTRU5aumf",
        "outputId": "0077f559-9218-489b-b6e3-13dc24ddaee4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([4, 10, 32])\n",
            "Output shape: torch.Size([4, 10, 32])\n"
          ]
        }
      ],
      "source": [
        "# Modelo\n",
        "d_model = 32\n",
        "num_heads = 4\n",
        "d_ff = 64\n",
        "\n",
        "encoder_layer = EncoderLayer(d_model, num_heads, d_ff)\n",
        "\n",
        "# Exemplo\n",
        "batch_size = 4\n",
        "seq_len = 10\n",
        "\n",
        "x = torch.randn(batch_size, seq_len, d_model)\n",
        "out = encoder_layer(x)\n",
        "\n",
        "print(f\"Input shape: {x.shape}\")    # (N, T, d_model)\n",
        "print(f\"Output shape: {out.shape}\") # (N, T, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "o5K1EaNm6gLT"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, num_layers, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            EncoderLayer(d_model, num_heads, d_ff, dropout)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, src_mask=None):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, src_mask)\n",
        "        return self.norm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnZz6i6Jaumg",
        "outputId": "f2c75662-13f0-4853-d417-b28a0c61cfec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([4, 12, 32])\n",
            "Encoder output: torch.Size([4, 12, 32])\n"
          ]
        }
      ],
      "source": [
        "# Modelo\n",
        "d_model = 32\n",
        "num_heads = 4\n",
        "d_ff = 64\n",
        "num_layers = 3\n",
        "\n",
        "encoder = Encoder(d_model, num_heads, d_ff, num_layers)\n",
        "\n",
        "# Exemplo\n",
        "batch_size = 4\n",
        "seq_len = 12\n",
        "\n",
        "x = torch.randn(batch_size, seq_len, d_model)\n",
        "out = encoder(x)\n",
        "\n",
        "print(f\"Input shape: {x.shape}\")     # (N, T, d_model)\n",
        "print(f\"Encoder output: {out.shape}\") # (N, T, d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKxOyrRBaumg"
      },
      "source": [
        "### DecoderLayer e Decoder\n",
        "\n",
        "Cada `DecoderLayer` possui três blocos com conexões residuais e normalização:\n",
        "\n",
        "1. **Self-attention mascarada**: impede que o token atual veja os futuros.\n",
        "2. **Cross-attention**: permite que o decoder atenda à saída do encoder.\n",
        "3. **Feed-forward**: transformação não linear local.\n",
        "\n",
        "As operações são:\n",
        "\n",
        "$$\n",
        "x_1 = \\text{LayerNorm}(x + \\text{Dropout}(\\text{SelfAttn}(x)))\n",
        "$$\n",
        "\n",
        "$$\n",
        "x_2 = \\text{LayerNorm}(x_1 + \\text{Dropout}(\\text{CrossAttn}(x_1, \\text{enc\\_out})))\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{Output} = \\text{LayerNorm}(x_2 + \\text{Dropout}(\\text{FFN}(x_2)))\n",
        "$$\n",
        "\n",
        "O `Decoder` empilha múltiplas `DecoderLayer`s após aplicar embedding e codificação posicional, e gera uma distribuição sobre o vocabulário via uma camada linear final."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6YYxGaRHaumh"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1, cross_attention=True):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.cross_attention = cross_attention\n",
        "        if cross_attention:\n",
        "            self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.feed_forward = FeedForward(d_model, d_ff, dropout)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model) if cross_attention else None\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, enc_out=None, tgt_mask=None, memory_mask=None):\n",
        "        # Masked Self-Attention\n",
        "        attn_out = self.self_attn(x, x, x, mask=tgt_mask)\n",
        "        x = x + self.dropout(attn_out)\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        # Cross-Attention (se habilitado)\n",
        "        if self.cross_attention and enc_out is not None:\n",
        "            attn_out = self.cross_attn(x, enc_out, enc_out, mask=memory_mask)\n",
        "            x = x + self.dropout(attn_out)\n",
        "            x = self.norm2(x)\n",
        "\n",
        "        # FeedForward\n",
        "        ff_out = self.feed_forward(x)\n",
        "        x = x + self.dropout(ff_out)\n",
        "        x = self.norm3(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSA3n3eCaumh",
        "outputId": "475a9893-de03-45e3-c00b-d2040c0d5383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target input: torch.Size([4, 7, 32])\n",
            "DecoderLayer output: torch.Size([4, 7, 32])\n"
          ]
        }
      ],
      "source": [
        "# Modelo\n",
        "d_model = 32\n",
        "num_heads = 4\n",
        "d_ff = 64\n",
        "\n",
        "decoder_layer = DecoderLayer(d_model, num_heads, d_ff)\n",
        "\n",
        "# Exemplo\n",
        "batch_size = 4\n",
        "src_len = 15\n",
        "tgt_len = 7\n",
        "\n",
        "enc_out = torch.randn(batch_size, src_len, d_model)  # saída do encoder\n",
        "tgt = torch.randn(batch_size, tgt_len, d_model)      # entrada do decoder\n",
        "\n",
        "tgt_mask = causal_mask(tgt_len)\n",
        "\n",
        "out = decoder_layer(tgt, enc_out, tgt_mask=tgt_mask)\n",
        "\n",
        "print(f\"Target input: {tgt.shape}\")        # (N, T_tgt, d_model)\n",
        "print(f\"DecoderLayer output: {out.shape}\") # (N, T_tgt, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LAiEpyuwaumh"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, num_layers, dropout=0.1, cross_attention=True):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([\n",
        "            DecoderLayer(d_model, num_heads, d_ff, dropout, cross_attention)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, enc_out=None, tgt_mask=None, memory_mask=None):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, enc_out, tgt_mask, memory_mask)\n",
        "        return self.norm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIgevVg5aumi",
        "outputId": "20085b3d-41c1-4fe8-e270-b6b8daaa0820"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoder input: torch.Size([4, 7, 32])\n",
            "Decoder output: torch.Size([4, 7, 32])\n"
          ]
        }
      ],
      "source": [
        "# Modelo\n",
        "d_model = 32\n",
        "num_heads = 4\n",
        "d_ff = 64\n",
        "num_layers = 2\n",
        "\n",
        "decoder = Decoder(d_model, num_heads, d_ff, num_layers)\n",
        "\n",
        "# Exemplo\n",
        "batch_size = 4\n",
        "src_len = 15\n",
        "tgt_len = 7\n",
        "\n",
        "enc_out = torch.randn(batch_size, src_len, d_model)\n",
        "tgt = torch.randn(batch_size, tgt_len, d_model)\n",
        "\n",
        "tgt_mask = causal_mask(tgt_len)\n",
        "\n",
        "out = decoder(tgt, enc_out, tgt_mask=tgt_mask)\n",
        "\n",
        "print(f\"Decoder input: {tgt.shape}\")     # (N, T_tgt, d_model)\n",
        "print(f\"Decoder output: {out.shape}\")    # (N, T_tgt, d_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h11k5rqWaumi"
      },
      "source": [
        "### Transformer\n",
        "\n",
        "A classe `Transformer` combina o encoder e o decoder em uma arquitetura completa de tradução seq2seq. Ela segue o formato proposto por Vaswani et al. (2017), onde:\n",
        "\n",
        "- O **encoder** processa a sequência de entrada e gera representações contextuais.\n",
        "- O **decoder** gera a saída passo a passo, utilizando essas representações.\n",
        "\n",
        "#### Máscaras\n",
        "\n",
        "Durante o `forward`, são geradas duas máscaras:\n",
        "- **Máscara de padding**: impede atenção a tokens vazios (`src == 0` ou `trg == 0`).\n",
        "- **Máscara causal (no-peak)**: impede que a atenção no decoder veja posições futuras, garantindo autoregressividade. Ela é definida por:\n",
        "\n",
        "$$\n",
        "\\text{nopeak}_{i,j} = \\begin{cases}\n",
        "1, & \\text{se } j \\leq i \\\\\n",
        "0, & \\text{caso contrário}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "O fluxo geral é:\n",
        "\n",
        "$$\n",
        "\\text{EncoderOutput} = \\text{Encoder}(src, src\\_mask)\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{Output} = \\text{Decoder}(trg, \\text{EncoderOutput}, src\\_mask, trg\\_mask)\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "z8JCJ3-naumi"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, num_encoder_layers, num_decoder_layers,\n",
        "                 src_vocab_size, tgt_vocab_size, max_len=5000, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # embeddings separados\n",
        "        self.src_embedding = nn.Embedding(src_vocab_size, d_model)\n",
        "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
        "\n",
        "        # positional encoding\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
        "\n",
        "        # encoder e decoder\n",
        "        self.encoder = Encoder(d_model, num_heads, d_ff, num_encoder_layers, dropout)\n",
        "        self.decoder = Decoder(d_model, num_heads, d_ff, num_decoder_layers, dropout)\n",
        "\n",
        "        # projeção final para o vocabulário de saída\n",
        "        self.fc_out = nn.Linear(d_model, tgt_vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt, src_mask=None, tgt_mask=None, memory_mask=None):\n",
        "        \"\"\"\n",
        "        src: (N, T_src) índices dos tokens da entrada\n",
        "        tgt: (N, T_tgt) índices dos tokens da saída\n",
        "        \"\"\"\n",
        "        # embeddings + posições\n",
        "        src_emb = self.src_embedding(src) * (self.src_embedding.embedding_dim ** 0.5)\n",
        "        src_emb = self.pos_encoding(src_emb)\n",
        "\n",
        "        tgt_emb = self.tgt_embedding(tgt) * (self.tgt_embedding.embedding_dim ** 0.5)\n",
        "        tgt_emb = self.pos_encoding(tgt_emb)\n",
        "\n",
        "        # encoder\n",
        "        memory = self.encoder(src_emb, src_mask)\n",
        "\n",
        "        # decoder\n",
        "        out = self.decoder(tgt_emb, memory, tgt_mask, memory_mask)\n",
        "\n",
        "        # projeção final para vocabulário alvo\n",
        "        logits = self.fc_out(out)  # (N, T_tgt, tgt_vocab_size)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqinx_iAaumj",
        "outputId": "649bdfcc-51eb-4808-99cb-adf446bd38a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source input shape: torch.Size([4, 12])\n",
            "Target input shape: torch.Size([4, 8])\n",
            "Output shape: torch.Size([4, 8, 150])\n"
          ]
        }
      ],
      "source": [
        "# Modelo\n",
        "d_model = 32\n",
        "num_heads = 4\n",
        "d_ff = 64\n",
        "num_encoder_layers = 2\n",
        "num_decoder_layers = 2\n",
        "src_vocab_size = 120   # ex: português\n",
        "tgt_vocab_size = 150   # ex: inglês\n",
        "max_len = 50\n",
        "\n",
        "model = Transformer(d_model, num_heads, d_ff, num_encoder_layers, num_decoder_layers, src_vocab_size, tgt_vocab_size, max_len)\n",
        "\n",
        "# Exemplo\n",
        "batch_size = 4\n",
        "src_len = 12\n",
        "tgt_len = 8\n",
        "\n",
        "src = torch.randint(0, src_vocab_size, (batch_size, src_len))  # tokens de entrada\n",
        "tgt = torch.randint(0, tgt_vocab_size, (batch_size, tgt_len))  # tokens de saída\n",
        "\n",
        "tgt_mask = causal_mask(tgt_len)\n",
        "\n",
        "out = model(src, tgt, tgt_mask=tgt_mask)\n",
        "\n",
        "print(f\"Source input shape: {src.shape}\")   # (N, T_src)\n",
        "print(f\"Target input shape: {tgt.shape}\")   # (N, T_tgt)\n",
        "print(f\"Output shape: {out.shape}\")         # (N, T_tgt, tgt_vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AiiiY5Taumj"
      },
      "source": [
        "## Tradução"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "d5Tey4xKaumj"
      },
      "outputs": [],
      "source": [
        "pairs = [\n",
        "    (\"olá\", \"hello\"),\n",
        "    (\"bom dia\", \"good morning\"),\n",
        "    (\"boa noite\", \"good night\"),\n",
        "    (\"como vai?\", \"how are you?\"),\n",
        "    (\"estou bem\", \"i am fine\"),\n",
        "    (\"obrigado\", \"thank you\"),\n",
        "    (\"até logo\", \"see you later\"),\n",
        "    (\"sim\", \"yes\"),\n",
        "    (\"não\", \"no\"),\n",
        "    (\"eu gosto de café\", \"i like coffee\"),\n",
        "    (\"ela gosta de música\", \"she likes music\"),\n",
        "    (\"nós vamos para a escola\", \"we go to school\"),\n",
        "    (\"ele está em casa\", \"he is at home\"),\n",
        "    (\"onde você está?\", \"where are you?\"),\n",
        "    (\"o gato está na cadeira\", \"the cat is on the chair\"),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "92eAZWtRaumk"
      },
      "outputs": [],
      "source": [
        "def build_vocab(sentences):\n",
        "    tokens = set()\n",
        "    for s in sentences:\n",
        "        tokens.update(s.lower().split())\n",
        "    stoi = {tok: i+4 for i, tok in enumerate(sorted(tokens))}\n",
        "    stoi[\"<pad>\"] = 0\n",
        "    stoi[\"<sos>\"] = 1\n",
        "    stoi[\"<eos>\"] = 2\n",
        "    stoi[\"<unk>\"] = 3\n",
        "    itos = {i: t for t, i in stoi.items()}\n",
        "    return stoi, itos\n",
        "\n",
        "# constrói vocabulários\n",
        "src_sentences = [pt for pt, en in pairs]\n",
        "tgt_sentences = [en for pt, en in pairs]\n",
        "\n",
        "src_stoi, src_itos = build_vocab(src_sentences)\n",
        "tgt_stoi, tgt_itos = build_vocab(tgt_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBLt4V50aumk",
        "outputId": "5324e92c-6871-4b0d-d0f7-beb286544429"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src_data: torch.Size([15, 10])\n",
            "tgt_data: torch.Size([15, 10])\n"
          ]
        }
      ],
      "source": [
        "def encode_sentence(sentence, stoi, max_len=10):\n",
        "    tokens = sentence.lower().split()\n",
        "    ids = [stoi.get(tok, stoi[\"<unk>\"]) for tok in tokens]\n",
        "    ids = [stoi[\"<sos>\"]] + ids + [stoi[\"<eos>\"]]\n",
        "    if len(ids) < max_len:\n",
        "        ids += [stoi[\"<pad>\"]] * (max_len - len(ids))\n",
        "    return ids[:max_len]\n",
        "\n",
        "max_len = 10\n",
        "data = [\n",
        "    (encode_sentence(pt, src_stoi, max_len), encode_sentence(en, tgt_stoi, max_len))\n",
        "    for pt, en in pairs\n",
        "]\n",
        "\n",
        "src_data = torch.tensor([pt for pt, en in data])\n",
        "tgt_data = torch.tensor([en for pt, en in data])\n",
        "\n",
        "print(\"src_data:\", src_data.shape)  # (N, max_len)\n",
        "print(\"tgt_data:\", tgt_data.shape)  # (N, max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "i8p7WaKbaumk"
      },
      "outputs": [],
      "source": [
        "src_vocab_size = len(src_stoi)\n",
        "tgt_vocab_size = len(tgt_stoi)\n",
        "\n",
        "d_model = 32\n",
        "num_heads = 4\n",
        "d_ff = 64\n",
        "num_encoder_layers = 2\n",
        "num_decoder_layers = 2\n",
        "\n",
        "model = Transformer(\n",
        "    d_model, num_heads, d_ff,\n",
        "    num_encoder_layers, num_decoder_layers,\n",
        "    src_vocab_size, tgt_vocab_size, max_len\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0euYmE_auml",
        "outputId": "26e37b19-52ef-45de-ecf7-76c5e77150ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 9.2133\n",
            "Epoch 20, Loss: 5.3336\n",
            "Epoch 30, Loss: 3.1691\n",
            "Epoch 40, Loss: 1.7818\n",
            "Epoch 50, Loss: 1.2067\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=tgt_stoi[\"<pad>\"])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 4\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for i in range(0, len(src_data), batch_size):\n",
        "        src_batch = src_data[i:i+batch_size]\n",
        "        tgt_batch = tgt_data[i:i+batch_size]\n",
        "\n",
        "        # entrada do decoder é sem o último token\n",
        "        tgt_in = tgt_batch[:, :-1]\n",
        "        # alvo é sem o primeiro token\n",
        "        tgt_out = tgt_batch[:, 1:]\n",
        "\n",
        "        tgt_mask = causal_mask(tgt_in.size(1))\n",
        "\n",
        "        logits = model(src_batch, tgt_in, tgt_mask=tgt_mask)\n",
        "\n",
        "        loss = criterion(\n",
        "            logits.reshape(-1, tgt_vocab_size),\n",
        "            tgt_out.reshape(-1)\n",
        "        )\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeQBs2PBauml",
        "outputId": "6b60dc12-2e81-49f6-8f22-864da97c9381"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<sos> i like coffee <eos>\n"
          ]
        }
      ],
      "source": [
        "def greedy_translate(model, src_sentence, max_len=10):\n",
        "    model.eval()\n",
        "    src_ids = torch.tensor([encode_sentence(src_sentence, src_stoi, max_len)])\n",
        "    tgt_ids = torch.tensor([[tgt_stoi[\"<sos>\"]]])\n",
        "\n",
        "    for _ in range(max_len-1):\n",
        "        tgt_mask = causal_mask(tgt_ids.size(1))\n",
        "        logits = model(src_ids, tgt_ids, tgt_mask=tgt_mask)\n",
        "        next_token = logits[:, -1, :].argmax(-1).unsqueeze(0)\n",
        "        tgt_ids = torch.cat([tgt_ids, next_token], dim=1)\n",
        "        if next_token.item() == tgt_stoi[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    return \" \".join([tgt_itos[i.item()] for i in tgt_ids[0]])\n",
        "\n",
        "print(greedy_translate(model, \"eu gosto de cafe\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZouDRT27aumm"
      },
      "source": [
        "## Exercícios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAhkZ7Inaumn"
      },
      "source": [
        "### Exercício 1: Classificação de Notícias com Transformer Encoder\n",
        "\n",
        "Implemente um módulo de classificação de texto utilizando **apenas o Encoder do Transformer**.  \n",
        "\n",
        "O modelo deve:  \n",
        "- Receber uma sequência de índices de tokens como entrada.  \n",
        "- Passar os embeddings pela pilha de camadas do Encoder.  \n",
        "- Agregar a informação da sequência por meio de um **pooling de média na dimensão temporal** (`seq_len`).  \n",
        "- Passar o vetor resultante por uma camada linear para prever a classe.  \n",
        "\n",
        "O dataset a ser utilizado é o **20 Newsgroups**, filtrado em algumas categorias de notícias.  \n",
        "Seu objetivo é treinar o classificador para prever a qual categoria pertence cada texto.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1u9aFy9faumn"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "categories = ['sci.electronics', 'comp.graphics', 'sci.med', 'rec.motorcycles']\n",
        "max_len = 100\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "# === Carregamento dos dados ===\n",
        "newsgroups_data = fetch_20newsgroups(subset='all', categories=categories)\n",
        "texts = newsgroups_data.data[:5000]\n",
        "labels = newsgroups_data.target[:5000]\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    texts, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# === Pré-processamento ===\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    tokens = text.split()\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def build_vocab(texts, min_freq=1):\n",
        "    word_freq = {}\n",
        "    for text in texts:\n",
        "        tokens = preprocess_text(text)\n",
        "        for token in tokens:\n",
        "            word_freq[token] = word_freq.get(token, 0) + 1\n",
        "\n",
        "    vocab = {'<pad>': 0, '<unk>': 1}\n",
        "    index = 2\n",
        "    for word, freq in word_freq.items():\n",
        "        if freq >= min_freq:\n",
        "            vocab[word] = index\n",
        "            index += 1\n",
        "    return vocab\n",
        "\n",
        "\n",
        "# === Vocabulário ===\n",
        "vocab = build_vocab(train_texts)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "\n",
        "# === Dataset ===\n",
        "class NewsGroupsDataset(Dataset):\n",
        "    def __init__(self, texts, labels, vocab, max_len):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.vocab = vocab\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def encode_text(self, text):\n",
        "        tokens = preprocess_text(text)\n",
        "        token_ids = [self.vocab.get(token, self.vocab['<unk>']) for token in tokens]\n",
        "        if len(token_ids) > self.max_len:\n",
        "            token_ids = token_ids[:self.max_len]\n",
        "        else:\n",
        "            token_ids += [self.vocab['<pad>']] * (self.max_len - len(token_ids))\n",
        "        return torch.tensor(token_ids, dtype=torch.long)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        token_ids = self.encode_text(text)\n",
        "        return token_ids, label\n",
        "\n",
        "\n",
        "# === DataLoaders ===\n",
        "train_dataset = NewsGroupsDataset(train_texts, train_labels, vocab, max_len)\n",
        "val_dataset = NewsGroupsDataset(val_texts, val_labels, vocab, max_len)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "BVpIQ-l2aumo"
      },
      "outputs": [],
      "source": [
        "class TransformerClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, num_heads, d_ff, num_layers, num_classes, max_len=100, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # Embedding dos tokens\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "        # Codificação posicional\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
        "\n",
        "        # Encoder do Transformer\n",
        "        self.encoder = Encoder(d_model, num_heads, d_ff, num_layers, dropout)\n",
        "\n",
        "        # Camada linear para classificação\n",
        "        self.fc_out = nn.Linear(d_model, num_classes)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, src_mask=None):\n",
        "        # x: (batch_size, seq_len)\n",
        "\n",
        "        # Embedding + escala\n",
        "        x = self.embedding(x) * (self.embedding.embedding_dim ** 0.5)\n",
        "\n",
        "        # Adiciona codificação posicional\n",
        "        x = self.pos_encoding(x)\n",
        "\n",
        "        # Passa pelo encoder\n",
        "        x = self.encoder(x, src_mask)\n",
        "\n",
        "        # Pooling de média na dimensão temporal\n",
        "        x = x.mean(dim=1)\n",
        "\n",
        "        # Dropout\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Camada linear para prever classes\n",
        "        logits = self.fc_out(x)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHhsEbqtaumo",
        "outputId": "bb95e17e-7ae2-4766-9302-d6098fa49e3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train Loss: 135.783, Train Acc: 0.315 | Val Loss: 33.746, Val Acc: 0.373\n",
            "Epoch 2/10 | Train Loss: 130.283, Train Acc: 0.415 | Val Loss: 32.158, Val Acc: 0.513\n",
            "Epoch 3/10 | Train Loss: 117.939, Train Acc: 0.547 | Val Loss: 28.976, Val Acc: 0.551\n",
            "Epoch 4/10 | Train Loss: 93.016, Train Acc: 0.663 | Val Loss: 24.814, Val Acc: 0.619\n",
            "Epoch 5/10 | Train Loss: 65.132, Train Acc: 0.783 | Val Loss: 21.284, Val Acc: 0.677\n",
            "Epoch 6/10 | Train Loss: 40.417, Train Acc: 0.874 | Val Loss: 20.893, Val Acc: 0.715\n",
            "Epoch 7/10 | Train Loss: 24.397, Train Acc: 0.928 | Val Loss: 20.436, Val Acc: 0.730\n",
            "Epoch 8/10 | Train Loss: 12.387, Train Acc: 0.975 | Val Loss: 21.308, Val Acc: 0.743\n",
            "Epoch 9/10 | Train Loss: 6.211, Train Acc: 0.990 | Val Loss: 24.598, Val Acc: 0.728\n",
            "Epoch 10/10 | Train Loss: 2.910, Train Acc: 0.998 | Val Loss: 23.817, Val Acc: 0.749\n"
          ]
        }
      ],
      "source": [
        "# Parâmetros do modelo\n",
        "d_model = 128\n",
        "num_heads = 4\n",
        "d_ff = 512\n",
        "num_layers = 2\n",
        "num_classes = len(categories)  # 4 categorias\n",
        "lr = 0.0001\n",
        "num_epochs = 10\n",
        "\n",
        "# Instancia o modelo\n",
        "model = TransformerClassifier(\n",
        "    vocab_size=vocab_size,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    d_ff=d_ff,\n",
        "    num_layers=num_layers,\n",
        "    num_classes=num_classes,\n",
        "    max_len=max_len\n",
        ").to(device)\n",
        "\n",
        "# Loss e otimizador\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# Loop de treino\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    for inputs, labels in train_dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Forward\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Métricas\n",
        "        total_loss += loss.item()\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_acc = correct / total\n",
        "\n",
        "    # Validação\n",
        "    model.eval()\n",
        "    val_loss, val_correct, val_total = 0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_dataloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            val_correct += (preds == labels).sum().item()\n",
        "            val_total += labels.size(0)\n",
        "\n",
        "    val_acc = val_correct / val_total\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
        "          f\"Train Loss: {total_loss:.3f}, Train Acc: {train_acc:.3f} | \"\n",
        "          f\"Val Loss: {val_loss:.3f}, Val Acc: {val_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKMOJOanaumo"
      },
      "source": [
        "### Exercício 2: Modelo de Linguagem com Transformer Decoder\n",
        "\n",
        "Implemente um **modelo de linguagem baseado apenas no Decoder do Transformer** (estilo *decoder-only*).  \n",
        "\n",
        "O modelo deve:  \n",
        "- Receber uma sequência de tokens como entrada.  \n",
        "- Utilizar máscara **causal** na auto-atenção, garantindo que cada posição só acesse os tokens anteriores e o próprio token.  \n",
        "- Prever o **próximo token em cada posição** (treinamento por *next token prediction*).  \n",
        "\n",
        "O corpus de treino será o fornecido na variável `corpus`.  \n",
        "Seu objetivo é treinar o modelo para gerar frases coerentes em português a partir de um prompt inicial.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VojLk-aBaumy",
        "outputId": "f21ef661-29e6-48f2-b72a-a9c4a8dba3fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamanho do corpus: 30000\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "def load_corpus_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    text = response.text\n",
        "    return text\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/wess/iotr/master/lotr.txt\"\n",
        "corpus = load_corpus_from_url(url)[:30000]\n",
        "\n",
        "print(\"Tamanho do corpus:\", len(corpus))\n",
        "\n",
        "# Tokenize o texto\n",
        "tokens = re.findall(r'\\b\\w+\\b', corpus.lower())\n",
        "\n",
        "# Constrói o vocabulário\n",
        "word_counts = Counter(tokens)\n",
        "vocab = sorted(word_counts.keys())\n",
        "\n",
        "special_tokens = [\"<pad>\", \"<unk>\", \"<sos>\", \"<eos>\"]\n",
        "word2idx = {tok: idx for idx, tok in enumerate(special_tokens, start=0)}\n",
        "\n",
        "for word in vocab:\n",
        "    if word not in word2idx:  # evita colisão\n",
        "        word2idx[word] = len(word2idx)\n",
        "\n",
        "idx2word = {idx: word for word, idx in word2idx.items()}\n",
        "vocab_size = len(word2idx)\n",
        "\n",
        "# Converte tokens para índices\n",
        "indices = [word2idx.get(w, word2idx[\"<unk>\"]) for w in tokens]\n",
        "\n",
        "# Gera as sequências\n",
        "sequence_length = 10\n",
        "inputs, targets = [], []\n",
        "\n",
        "for i in range(len(indices) - seq_len):\n",
        "    seq = indices[i:i+seq_len]\n",
        "    tgt = indices[i+1:i+seq_len+1]\n",
        "\n",
        "    # insere <sos> no início do input, <eos> no fim do target\n",
        "    seq = [word2idx[\"<sos>\"]] + seq\n",
        "    tgt = tgt + [word2idx[\"<eos>\"]]\n",
        "\n",
        "    inputs.append(seq)\n",
        "    targets.append(tgt)\n",
        "\n",
        "inputs = torch.tensor(inputs, dtype=torch.long)\n",
        "targets = torch.tensor(targets, dtype=torch.long)\n",
        "\n",
        "# Cria o dataset e o dataloader\n",
        "batch_size = 32\n",
        "dataset = TensorDataset(inputs, targets)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "lA2rYTC8aumz"
      },
      "outputs": [],
      "source": [
        "class LanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, num_heads, d_ff, num_layers, max_len=100, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # Embedding dos tokens\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "        # Codificação posicional\n",
        "        self.pos_encoding = PositionalEncoding(d_model, max_len)\n",
        "\n",
        "        # Decoder do Transformer (sem cross-attention)\n",
        "        self.decoder = Decoder(d_model, num_heads, d_ff, num_layers, dropout, cross_attention=False)\n",
        "\n",
        "        # Camada linear para prever o vocabulário\n",
        "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, tgt_mask=None):\n",
        "        # x: (batch_size, seq_len)\n",
        "\n",
        "        # Embedding + escala\n",
        "        x = self.embedding(x) * (self.embedding.embedding_dim ** 0.5)\n",
        "\n",
        "        # Adiciona codificação posicional\n",
        "        x = self.pos_encoding(x)\n",
        "\n",
        "        # Passa pelo decoder com máscara causal\n",
        "        x = self.decoder(x, tgt_mask=tgt_mask)\n",
        "\n",
        "        # Dropout\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Projeção para o vocabulário\n",
        "        logits = self.fc_out(x)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E-j8abdaumz",
        "outputId": "5ddca4e3-f2ff-4ce4-a99f-73ec90fde44f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 856.722\n",
            "Epoch 2, Loss: 590.457\n",
            "Epoch 3, Loss: 437.083\n",
            "Epoch 4, Loss: 353.741\n",
            "Epoch 5, Loss: 291.030\n",
            "Epoch 6, Loss: 249.787\n",
            "Epoch 7, Loss: 224.011\n",
            "Epoch 8, Loss: 210.182\n",
            "Epoch 9, Loss: 198.697\n",
            "Epoch 10, Loss: 190.592\n",
            "Epoch 11, Loss: 183.717\n",
            "Epoch 12, Loss: 181.170\n",
            "Epoch 13, Loss: 177.458\n",
            "Epoch 14, Loss: 175.195\n",
            "Epoch 15, Loss: 172.907\n",
            "Epoch 16, Loss: 170.872\n",
            "Epoch 17, Loss: 168.454\n",
            "Epoch 18, Loss: 166.928\n",
            "Epoch 19, Loss: 164.781\n",
            "Epoch 20, Loss: 164.237\n",
            "Epoch 21, Loss: 162.480\n",
            "Epoch 22, Loss: 161.398\n",
            "Epoch 23, Loss: 160.247\n",
            "Epoch 24, Loss: 158.074\n",
            "Epoch 25, Loss: 157.505\n",
            "Epoch 26, Loss: 158.013\n",
            "Epoch 27, Loss: 156.149\n",
            "Epoch 28, Loss: 156.312\n",
            "Epoch 29, Loss: 155.144\n",
            "Epoch 30, Loss: 154.914\n",
            "Epoch 31, Loss: 154.040\n",
            "Epoch 32, Loss: 153.297\n",
            "Epoch 33, Loss: 151.944\n",
            "Epoch 34, Loss: 151.169\n",
            "Epoch 35, Loss: 151.699\n",
            "Epoch 36, Loss: 150.581\n",
            "Epoch 37, Loss: 150.226\n",
            "Epoch 38, Loss: 149.753\n",
            "Epoch 39, Loss: 148.578\n",
            "Epoch 40, Loss: 149.075\n",
            "Epoch 41, Loss: 148.735\n",
            "Epoch 42, Loss: 147.684\n",
            "Epoch 43, Loss: 147.412\n",
            "Epoch 44, Loss: 145.984\n",
            "Epoch 45, Loss: 145.676\n",
            "Epoch 46, Loss: 145.660\n",
            "Epoch 47, Loss: 145.751\n",
            "Epoch 48, Loss: 145.226\n",
            "Epoch 49, Loss: 144.972\n",
            "Epoch 50, Loss: 144.565\n"
          ]
        }
      ],
      "source": [
        "# Modelo\n",
        "d_model = 128\n",
        "num_heads = 4\n",
        "d_ff = 512\n",
        "num_layers = 2\n",
        "max_len = seq_len + 1  # Inclui <sos>\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Instancia o modelo\n",
        "model = LanguageModel(\n",
        "    vocab_size=vocab_size,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    d_ff=d_ff,\n",
        "    num_layers=num_layers,\n",
        "    max_len=max_len\n",
        ").to(device)\n",
        "\n",
        "# Loss e otimizador\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=word2idx[\"<pad>\"])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Loop de treino\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    for x, y in dataloader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        mask = causal_mask(x.size(1)).to(device)\n",
        "        logits = model(x, tgt_mask=mask)\n",
        "        loss = criterion(logits.view(-1, vocab_size), y.view(-1))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "zsYUjllRaum0"
      },
      "outputs": [],
      "source": [
        "def generate_text(model, prompt, word2idx, idx2word, max_new_tokens=20, device=\"cpu\"):\n",
        "    model.eval()\n",
        "\n",
        "    # Converte prompt em índices\n",
        "    tokens = re.findall(r'\\b\\w+\\b', prompt.lower())\n",
        "    ids = torch.tensor([[word2idx.get(tok, word2idx[\"<unk>\"]) for tok in tokens]], device=device)\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        # Máscara causal\n",
        "        mask = causal_mask(ids.size(1)).to(device)\n",
        "\n",
        "        # Forward\n",
        "        with torch.no_grad():\n",
        "            logits = model(ids, tgt_mask=mask)\n",
        "\n",
        "        # Pega último token previsto\n",
        "        next_id = logits[:, -1, :].argmax(-1).unsqueeze(0)\n",
        "\n",
        "        # Concatena ao input\n",
        "        ids = torch.cat([ids, next_id], dim=1)\n",
        "\n",
        "        # Para se encontrar\n",
        "        if next_id.item() == word2idx[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    # Decodifica para palavras\n",
        "    out_tokens = [idx2word[i.item()] for i in ids[0]]\n",
        "    return \" \".join(out_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxcyRADlaum0",
        "outputId": "be8e5c1d-8d1a-4441-89e0-935266bb7dfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated: the <eos>\n"
          ]
        }
      ],
      "source": [
        "prompt = \"the\"\n",
        "generated = generate_text(model, prompt, word2idx, idx2word, max_new_tokens=10, device=device)\n",
        "print(\"Generated:\", generated)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}